\chapter{Design}
\label{ch:design}

\section{The Julia language}

I chose to write the project in Julia \citep{julia}, A dynamically typed, Just-In-Time compiled language, This allows it to have both the speed of a compiled language and the flexibility of an interpreted one. This made it an excellent choice for my framework as I could quickly iterate on the design, without compromising on the performance of computationally expensive operations like querying the queue (see \fullref{sec:queue}).

Julia also has excellent integrations with the C language, which allowed me to use the libpcap library \citep{libpcap} inside of a Julia program, this can be seen in action with the use of \inline{ccall} in figure \ref{fig:raw_sock}.

The high-level, dynamic nature of Julia also lends itself to the ease of extending the framework with new covert channels, the intricacies of this process are discussed in \fullref{sec:new_channels}.

\section{Packet capture}
\label{sec:packet_capture}

For the framework to adapt to the network environment, it must be able to listen to the network traffic.
I concluded that one of two options would be best suited to my needs:

\begin{itemize}
    \item libpcap
    \item A raw socket
\end{itemize}

\subsection{raw sockets}

Raw sockets provide direct access to low-level protocols, allowing a program to read packets down to layer two, generally the Ethernet header. 

This approach is standalone; it does not require external libraries to operate, so the program would not need pre-existing libraries installed on the system. This is particularly important in some of the applications of covert channels.

There is very little code complexity involved in setting up a raw socket:

\begin{figure}[h]
\begin{lstlisting}[language=JuliaLocal, style=julia]
# Capture the entire packet (AF -> Address Family)
const AF_PACKET = Cint(17) 
# Raw listening socket
const SOCK_RAW = Cint(3)
# Capture all ethernet frames
const ETH_P_ALL = Cint(0x0300)

socket = fdio(ccall(:socket,
    Cint, # Return type
    (Cint, Cint, Cint), # Argument types
    AF_PACKET, SOCK_RAW, ETH_P_ALL # Arguments
))
packet = read(socket)
\end{lstlisting}
\caption{Raw socket listener implementation}
\label{fig:raw_sock}
\end{figure}
Julia will read the socket pipe until an EOF is found, which marks the end of a packet; this lightweight and simplistic implementation means the construction of this listener has little cost to system resources, and thus it can be easily applied to a variety of use cases.

\subsection{libpcap}

libpcap is a cross-platform library for low-level network monitoring \citep{libpcap}. 
There are several benefits to using libpcap, the first being the ease of implementation, libpcap provides a simple API for capturing packets, allowing for a callback function to be called when a packet is captured, this function is passed the capture header, packet pointer, and user data if required.

Because of Julia's ability to integrate seamlessly with C and its libraries, the callback function could be written in Julia, removing the need to write any C code. The benefit of using a library is that it is appropriately optimised. libpcap creates a memory-mapped ring buffer for asynchronous packet reception \citep{packet_7}, this allows the user space to read the packet data without the need for system calls, and the shared buffer also reduces the number of copies required.

While the platform-independent nature of libpcap is beneficial, the scope of this project is limited to Linux to manage the scope, and thus this will not be considered as part of my evaluation.

\subsection{Conclusion}

Both raw sockets and libpcap are viable options for packet capture, however, libpcap has a few advantages, the factor that swayed my decision was the support for the Berkeley Packet Filter (BPF). BPFs are register-based "filter machines" \citep{BPF} that make filtering packets incredibly efficient, this is particularly useful for this project as it allows for the filtering of packets to be done in the kernel, which reduces the number of packets that need to be processed by the program. Specifically, this means the receiver can filter traffic so it only has to process packets that are destined for it, reducing the overhead. In some cases, however, we will want to be able to capture packets without disrupting the main queue of packets, and the filters that are put on the queue. In these cases, I will opt to use the raw socket implementation, as its reduced code complexity (compared to searching the queue) will, in turn, reduce the complexity of the codebase. There are some other advantages to using the raw socket, but I will discuss them in context in \ref{sec:integrity_impl}.

\section{Packet processing}
\label{sec:packet_processing}

When packets are captured, we want to process them into objects so we can idiomatically access their properties. Specifically, we want to process them into a \inline{Packet} object, that holds the capture header, and a \inline{Layer} object. The layer is made up of a \inline{Layer\_type} enum, the layer header, and the payload. The payload can be either another \inline{Layer} or a \inline{Vector\{UInt8\}}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/packet_structure.png}
    \caption{Packet structure}
    \label{fig:packet_structure}
\end{figure}

A function, \inline{packet\_from\_pointer} takes the pointer given by libpcap, and the length of the packet. It iteratively processes the packet, creating an \inline{Layer} struct of each layer, and appending to the previous \inline{Layer}, incrementing the \inline{Layer\_type} enum as it goes. The headers defined have two helper functions to assist this process, \inline{get\_offset} which returns the size of the header, and \inline{get\_protocol} which returns the protocol embedded in the header, allowing the next layer to be processed.

The \inline{Header} class is an abstract type, generalising all headers, it should also be noted the packet definition looks like this:

\begin{lstlisting}[language=JuliaLocal, style=julia]
struct Packet
    cap_header::Capture_header
    layer::Layer{Ethernet_header}
end
\end{lstlisting}

To assist this process there is a tree defined that maps the protocol number to the header type, and the protocols in the layer above it. This makes the addition of protocols easy for the user, it is mostly just copying the structure of the protocol from the relevant header file, adding it to the tree, and two simple helper functions that just access fields.


\section{The Packet Queue}
\label{sec:queue}

The queue is essential to the operation of the framework, it is how packets that are captured by the listening thread, are retrieved by the main thread for processing.

Initially, I was using a \inline{Channel} data structure, it is a thread-safe, waitable, First-in-First-out queue \citep{julia} that worked for the most part. However, it introduced a bug into my codebase which meant the listening thread would block the main thread while it was waiting for packets, thus the covert channel would not run in a silent environment.

While this wasn't a huge problem, since a covert channel is quite exposed on a silent network, it is not ideal. I eventually deduced that I was improperly accessing the properties of the structure, I was attempting to get the whole queue without removing the items, so I just took it from the underlying array. Unfortunately, the \inline{Channel} is locked by default, and thus the main thread was blocked until the listening thread pushed something to the queue.

While I knew this action was not properly thread-safe, meaning I would likely be operating with stale data, it wasn't of great importance that my queue was truly up-to-date, as I was taking a rolling average of 150 packets anyway. I didn't realise that it would cause the main thread to be intermittently blocked, additionally, this unusual behaviour meant that it was difficult to debug, especially since my print statements were reliant on packets being received by the listening thread, which caused a lot of debugging cycles to be performed.

My solution to this was to implement a new, more idiomatic data structure, the \inline{CircularChannel}. This is a thread-safe, waitable, First-in-First-out queue that behaves like a circular buffer so that it overwrites the oldest item when it is full.

\begin{figure}[!h]
    \begin{minipage}{0.5\textwidth}
        \centering
        \begin{minted}{julia}

packet = get_packet()
if isfull(queue)
    take!(queue)
end
put!(queue, packet)

        \end{minted}
        \captionof{listing}{Old "Channel" implementation}
    \end{minipage}
    \begin{minipage}{0.5\textwidth}
        \centering
        \begin{minted}{julia}

packet = get_packet()
put!(queue, packet)

        \end{minted}
    \captionof{listing}{New "CircularChannel" implementation}
    \end{minipage}
\end{figure}
\label{lst:queue_comparison}

By implementing the \inline{put!} and \inline{take!} functions for my new data structure, I was able to avoid changing the majority of my existing implementation, needing only to replace the type from \inline{Channel} to \inline{CircularChannel}. I also simplified the code for the producer (packet listener) as seen in the comparison above (figure \ref{lst:queue_comparison}). The \inline{get\_queue\_data} function that I was previously using to illegally access the properties of the channel was called everywhere I needed to access the whole queue, so I only had to alter that function to access the \inline{CircularChannel} in a thread-safe manner. 

I efficiently achieved this waiting using \inline{Conditions}, which are locks that implement \inline{wait} and \inline{notify} methods that block (reducing resource usage) and release threads, respectively, based on the status of the condition. This allows my main thread to wait for the listening thread to push a packet to the queue, and then continue processing the packet (for the receiver only).

\subsection{Queriability}
\label{sec:queriability}

One of my goals for the project was to allow any type of covert channel to be used in the framework, regardless of classification. Ultimately, this meant I was going to have to take a dynamic approach to initialising and using channels. I concluded that it was best to be able to query the channel for certain properties in packets, like the destination port or the packet size.

I implemented a rudimentary query system, that allowed for querying of properties captured by the framework (known header values), these properties could be combined with simple logical operators (AND, OR) to sufficiently complex queries. An extract of Faucet's documentation gives an example of what these queries look like:

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{fig/docs_query_queue.png}
    \caption{A snippet from the Faucet documentation}
    \label{fig:doc_snippet}
\end{figure}

\section{The arrangement}
\label{sec:target}

Covert communication is reliant on a preshared arrangement \citep{DoCCaS}, this arrangement is a set of parameters that both parties will assume the other is using, hereon called the "target", it contains the following information:

\begin{itemize}
    \item The IP Address of the target.
    \item The covert methods to use.
    \item The AES Pre-shared key.
    \item The Initial Vector to use.
\end{itemize}

The IP address is where the sender will send the packets and the address that the receiver will listen on. In theory, this address does not have to be the address of the target, as long as the target can see that endpoint, but I cannot test this due to limitations in the testing environment. The covert methods are the channels that will be used for communication, they are referenced by their index in the array of covert methods, and thus the order of the covert methods is important.
The AES pre-shared key is used to encrypt (and subsequently decrypt) the data, and the initial vector is used to initialise the AES encryption, both communication parties must know these values \citep{GUCCA}.

\section{Sending packets}
\label{sec:sending_packets}

Sending packets is an important aspect of the framework, as outgoing packets must be completely composable to permit all covert channels. While Julia does have some socket functionality, it is not sufficient for the project as it is too high level, my implementation instead uses a lightweight TCP/IP stack design. The principle is the user can supply the protocols to use, and a dictionary of fields and values for each of the layers, The function will then construct the packet, filling in an informed manner.

For example, in an IP header, source and destination fields will default to the local IP and target's IP respectively, But in a TCP Header, the ISN will be random. If flags are set, but their respective fields are not filled, they will also be randomised. This allows for the user to specify the fields they want to be set, and the rest will be filled in a way that is consistent with the protocol, however, it should be noted that some of these randomised fields do not have uniform distributions, and thus may be more suspicious than others, but this is out of the scope of my project.
 
Since the filling of these additional fields is done at execution time, a "skeleton" packet can be created that outlines a basic packet, then this skeleton can be used multiple times without having random fields being static, it is also useful with packet checksums, as this burden is not passed to the user. I make use of this functionality in the use of covert modules, as outlined in \fullref{sec:covert_modules}.

The packets themselves are sent over a raw socket, this allows for the packet to be sent without the kernel imposing checks on its validity (such as the checksum), this is important for the operation of some covert channels, as they create packets that would otherwise be dropped by the kernel (sometimes because of firewalls). For a packet to be sent over a raw socket at the link layer (ethernet) it needs to be sent with a \inline{sockaddr\_ll} struct, outlined in \cite{packet_7} the majority of these fields are not required, or are unlikely to change (The physical layer protocol) and thus can be hardcoded, only two fields need to be populated dynamically, the interface index and the destination mac address. The interface used is the one that the queue listens on, and the destination MAC can be taken from the packet.

The packets can then be sent to the raw socket using the \inline{sendto} function, taking the socket, packet and \inline{sockaddr\_ll} as arguments.

\section{Providing context to the sender}
\label{sec:context}

Many of the sender's functions are reliant on the context of the environment, this environment is constructed as a dictionary of values that are passed to the sender. This dictionary contains the following values:

\begin{itemize}
    \item The desired secrecy of the channel (User argument).
    \item The interface to use (see \fullref{sec:sending_packets})
    \item The socket to send packets over.
    \item Information about the route to the target.
    \item The queue
\end{itemize}

I will discuss the desired secrecy argument in \fullref{sec:decision_algorithm}, and the interface has already been discussed in the construction of the \inline{sockaddr\_ll} struct (see \fullref{sec:sending_packets}). The socket is simply a raw socket, it does not carry context and thus could be recreated at each use, but that requires calls to the kernel, and this approach has very little technical overhead.

The information about the target essentially outlines the default path to follow for a target, like the physical address of the target, or the gateway to use to reach the target. while this does not apply to all channels, it is used for many of them, and not worth recalculation for each packet.

The queue is also exposed here, since it accounts for most of the context of the sender, compiling these contextual values into a single dictionary makes it easier to pass around, and allows for the sender to be more idiomatic.

\section{Design of covert modules}
\label{sec:covert_modules}

A covert module is a set of functions that are used to implement a covert channel. For the framework to work effectively, the addition of covert modules must be a process that is both simple and idiomatic, but sufficiently flexible to allow for any type of covert channel to be implemented. Since I cannot predict the nature (and thus the requirements) of the covert channels that will be implemented, A dynamic approach is required.

Covert modules are implemented using:
\begin{itemize}
    \item An \inline{init} function.
    \item An \inline{encode} function.
    \item A \inline{decode} function.
    \item An instance of the \inline{covert\_method} struct.
\end{itemize}

The \inline{init} method is called when the module is loaded, it is used to initialise the channel, and it returns a set of keyword arguments that are to be passed to the \inline{encode} functions. The most common of these arguments will be \inline{template}, which outlines the skeleton and structure of a packet that the covert channel lives in, omitting the fields that are to be used in the channel, as outlined in \fullref{sec:sending_packets}. This function is passed the queue (see \nameref{sec:queue}) as an argument, allowing it to adapt to the environment.

Covert channels can be adapted to the network on a sub-method level to improve covertness, a good example of this is using IPv4 vs IPv6 as the internet protocol, for covert channels that exist in all other layers this does not affect their operation, but does allow them to be better suited to the network. I specifically chose to implement the TCP Acknowledgement bounce covert channel to showcase this flexibility in the framework. By using a local TCP server to bounce the packets, the channel must be aware of the network to discover these hosts. For this to be possible, the \inline{init} function must have the environment exposed to it, this is done by passing the environment dictionary outlined in \fullref{sec:context} to the \inline{init} function.

In the case of the TCP Acknowledgement bounce covert channel, the queue is taken from the environment dictionary, and the \inline{init} function will use this to listen for the destination of TCP packets, and it will return a template that has the destination mac, ip and port set to the local server.

The \inline{encode} function is called for each packet to be encoded, it is passed the keywords arguments from \inline{init} and the payload to put into the packet. The function will then return a full packet template, that can be converted into a vector of bytes, and sent over the network.

The \inline{decode} function is called to extract the payload from a packet, it doesn't require any other arguments as it just returns the field of the packet object that has the payload in it. This function does not need to perform any validity check, as the framework will verify that the packet could contain the payload before calling this function.

The \inline{covert\_method} struct holds metadata about a channel, and is comprised of five fields:
\begin{itemize}
    \item The name of the covert channel.
    \item The TCP/IP layer it operates on.
    \item The protocol in that layer it operates on.
    \item How covert it is, on a scale of 1 - 10.
    \item The bit capacity of the channel.
\end{itemize}
\label{itm:covert_method}

These allow the framework to seamlessly integrate with the covert channel, for example, the bit capacity is used for crafting payloads for the channel, removing this burden from the module. The name of the channel is used in \fullref{sec:target} to ensure both parties are using the same channels.

The layer and protocol are used by the receiver side of the framework to filter out packets that are not relevant to the covert channel, so the \inline{decode} function is only called on valid packets, so error handling can be omitted from covert modules unless they are particularly complex.

All of the fields are used to create an informed decision on which covert channel to use, as outlined in \fullref{sec:decision_algorithm}.

\subsection{Covert module validation}

Covert modules need to be validated before they can be used in the framework, this is done to ensure they are compatible with the preshared arrangement (defined in \fullref{sec:target}). There are three checks to be performed:

\begin{itemize}
    \item The smallest channel is not smaller than the minimum channel size.
    \item The number of channels is not too large to be represented by the minimum channel size.
    \item The channels are in the same order they appear in the arrangement.
\end{itemize}

The first check prevents very small channels from being used in the framework, as they are not large enough to carry the \fullref{sec:microprotocols}. The second check prevents too many channels from being used, this is because the channels are referenced by their index in the \inline{covert\_methods} array, and the micro protocols are limited by size on how many indexes they can represent.

Since the channels are referenced by their index, both the sender and receiver need to be using the same channels, in the same order, this is why the third check is required.

\section{Decision algorithm}
\label{sec:decision_algorithm}

The decision algorithm is responsible for the adaptive nature of the framework, it is used to decide which covert channel is best suited to the current environment.
The algorithm is an empirically derived function that takes the following arguments:

\begin{itemize}
    \item $E_s$ - The desired secrecy of the environment
    \item $L$ - An array of dictionaries, describing the protocol usages in the environment
    \item $E_r$ - The rate of packets in the environment
    \item $E_h$ - The number of active hosts in the environment
    \item The covert methods to choose from.
    \item Penalised methods.
    \item Index of the current method.
\end{itemize}

While $E_s$ is a user argument, $L$, $E_r$, and $E_h$ are derived from \fullref{sec:queue}. Penalised methods have a penalty on their score, to discourage the algorithm from picking them again, why these methods are penalised is discussed in \fullref{sec:penalising}, and the index of the current method is used to discourage the constant switching of channels.

The output of this algorithm is two arrays, $R$ and $S$ where $R_i$ is the rate of the $i^{th}$ covert channel, and $S_i$ is the score of the $i^{th}$ covert channel.

For a deeper understanding of the algorithm, see \fullref{sec:algorithm_impl}.

\subsection{Covertness}

$C_i$ is the covertness of the $i^{th}$ covert method, it is calculated using the covertness of the channel defined in \fullref{itm:covert_method}, and the desired secrecy of the environment, a user argument. The covertness of the method is correlated to the desired secrecy of the environment, and thus it is not just the covertness of the channel.

This way, methods that are more covert than the desired are given a score boost and methods that are less covert than the desired are penalised.

The covertness of the channel is calculated using the following equation:

\begin{equation}
    C_i = 1 - \frac{E_s - M_c}{10}
\end{equation}

Where $M_c$ is the covertness of the channel, and $E_s$ is the desired secrecy of the environment.

If the desired secrecy was 5, and the channel had a covertness of 3, $C_i$ would be 1.2 (a 20\% boost to the score). Conversely, if the desired secrecy was 10 and the channel had a covertness of 3, $C_i$ would be -0.7 (a 70\% penalty to the score).

The reason to not just prevent the use of more covert channels is that the covertness of the channel is also correlated to its use in the environment, if a cover text is very prominent in the environment, the covertness of the method will be higher and thus a better choice than a slightly more covert, but less common method.

$C_i$ is within the interval $[0.1, 1.9]$ (-90\% to 90\% penalty/boost).

\subsection{Rate calculation}

The rate of a channel determines how often packets should be sent over that channel while remaining covert. This is a function of the rate of packets in the environment, the number of active hosts in the environment, and the covertness of the channel.

The rate of the channel is calculated using the following equation:

\begin{equation}
    R_i = \frac{E_h}{P_i * E_r * \frac{C_i}{2} }
\end{equation}

Where $P_i$ is the percentage of packets in the environment that use the protocol of the $i^{th}$ channel, and $E_r$, $E_h$ and $C_i$ are as defined above. The reason for the $\frac{C_i}{2}$ term is to prevent the rate from being higher than the estimated protocol output per host per second ($\frac{E_h}{P_i * E_r}$) as this would cause the channel be using a protocol more than the average host, and thus be more suspicious.

$R_i$ is within the interval $[0, \infty)$.

\subsection{Score calculation}

The score of a method is a function of its use in the environment, its capacity, and its covertness.
The score is calculated using the following equation:

\begin{equation}
    S_i = P_i * B_i * C_i
\end{equation}

Where $P_i$ is the percentage of packets in the environment that use the protocol of the $i^{th}$ channel and $B_i$ is the bit capacity of that channel. $C_i$ is as defined above.

The $P_i * B_i$ term is the effective bandwidth of the channel, we'd like our covert communication to be as fast as possible, and thus the higher the effective bandwidth, the better. We again factor in the relative covertness ($C_i$) of the channel to the desired secrecy.

\subsection{Preventing constant switching}

The index of the current method is used to prevent the constant switching of channels, this is done by giving a bonus of 10\% to its score, this percentage is arbitrary, but it is large enough to work and small enough to allow for the channel to be switched if it is not covert enough.

For a method to be chosen, it must be more than \%10 better than the current channel, if it exceeds this threshold it will be chosen, and will gain a +10\% bonus to its score, and the previous channel will lose its bonus, effectively putting a \%20 gap between them. This encourages the channel not to change again unless it is significantly better than the current channel.

\section{Microprotocols}
\label{sec:microprotocols}

The adaptive covert channel is reliant on the underlying protocols, these protocols are used to implement:
\begin{itemize}
    \item Describing the nature of a payload
    \item Starting communication
    \item Ending communication
    \item Switching active channel (The one being used for communication)
    \item Verifying integrity of the communication
    \item Discarding chunks of data that have been corrupted
    \item Recovering from a disconnection in communication
\end{itemize}
\label{itm:microprotocols}

A sentinel signal is sent to begin and end communication, this way they can both share the same micro protocol, once a sentinel is received, then the receiver starts to build the context of the communication, like the received data and the current chunk.

Data is sent in chunks, a chunk is effectively a buffer of data that has not had its integrity verified yet, once the verification of the chunk has passed, it can be committed to the main buffer, and the chunk can be emptied ready for the next set of data. Both the sender and receiver keep track of this chunk so the state of communication is atomic between the two parties.

In order to implement these protocols effectively, using the contextual design proposed in \citep{rfc1144}, packets need to describe their nature, I decided to implement this using a single bit, at the start of the payload. 0 or 1 indicate whether the packet is data or metadata, respectively. Protocols are implemented as metadata and are of adaptive length, the size of these protocols is a function of the number of underlying channels that may be used. The minimum channel size is $1 + \lfloor log_2{M_c + 1} \rfloor$ where $M_c$ is the number of underlying covert methods.

For some protocols, it is beneficial to use more than the minimum channel size, for example, when verifying the integrity of a channel an offset can follow the protocol. The offset is assumed to be 0 if it is not present, but when it is present it improves the covertness of the channel, exactly why this is the case is discussed in \fullref{sec:integrity}. For the chunk discarding protocol, the space following the protocol is filled with payload data, this is beneficial to the covertness of the channel as the sender has to resend the previous data segments, and without this offset the fields would be repeated, which would be suspicious to an observer.

For protocols that do not have auxiliary data to be sent with them, the following data bits are assigned at random, this has no benefit to the covertness of the channel since the payload is encrypted and thus appears random, however, the added complexity of the protocol for the tradeoff of bits did not seem worth it.

\subsection{Protocol compression}

It is important to minimise the size of micro protocol headers, so they are negligible to the size of the payload \citep{DRiCCBoCP}, we will achieve this by compressing the protocols.

The compression technique outlined in \fullref{sec:DRiCCBoCP} is Huffman coding, which is a simple lossless compression technique that maps the protocols to a number, then the binary representation of that number can be used, however, I do not think this method of compression is best suited to the framework. The problem with Huffman coding arises when the distribution of protocol is not uniform, In my case the majority of traffic will be data, and thus by using only the first bit to declare it as data, the rest of them will be data. The consequence of this is the metaprotocols will be slightly larger than otherwise, but since by their nature they are less frequent than data, this is a worthwhile tradeoff.

\subsection{Consequence of this approach}
\label{sec:mp_consequence}

Unfortunately, using a single bit to denote data means that the original payload is not taken in whole bytes, A packet of n bits will carry n-1 bits of data. This creates an issue when reading the payload because the bits must be read out of alignment. This problem is exacerbated by the unknown nature of the packets pre-communication, as some channels have higher bit capacities, and along with the introduction of chunk retransmission, it is not feasible to precompute the possible payloads. The solution I found for this problem was to store the payload as a bitstring, the base two representation of the number in string form, and then read the desired number of bits from the string. There is a time and space cost of storing the payload like this, and in hindsight using a \inline{BitVector} would be more performant, but this cost is negligible and the code is easier to follow than using bit shifts to read the bits.

\section{Transmission padding}
\label{sec:transmission_padding}

The common approach to adding bits of padding is to append the data with a 1 and fill any remaining space with 0's, the cost of this (minimum number of bits added to the payload) is 1, which is the lowest possible. While this application works well for non-covert scenarios, it can create particularly suspicious-looking payloads, the worst-case scenario of this is an entire packet with a single 1 followed by 0's to fill capacity.

In this paper I will propose a solution that is better suited to covert channels, it does have a higher space cost, however, the benefit is more of the data is random, and sometimes the proficiency of a protocol must be sacrificed in favour of covertness \citep{oCDCCEDNA}. The cost is logarithmically proportional to the size of the data, although if the data has fixed size increments (a common one would be bytes as most payloads will be byte data) then the length can be divided by this number to reduce its costs. In my case, the AES encryption means that the data is a multiple of the key size (128 bits) so the equation of my cost complexity would be $log_2(l/128)$ where $l$ is the length of the encrypted data.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/Padding_diagram.pdf}
    \caption{Padding diagram}
    \label{fig:padding_diagram}
\end{figure}

The padding method works by storing the (reduced) size of the encrypted payload after the encrypted payload, and the remaining padding can almost be random. The data is read from right to left, and the sender must ensure that the first valid length is the one that describes the payload. For scenarios where the largest payload size is smaller than the smallest increment size, this is not necessary. In figure \ref{fig:padding_diagram} $L$ is the encrypted payload, and the length of $L$ is a binary representation of the length divided by the increment size. The padding is random data.

Both of these padding methods will be tested and compared in \fullref{sec:padding_testing}.

\section{Verifying communication integrity}
\label{sec:integrity}

Verifying the integrity of communication is essential to the operation of the framework, it allows the communication channel to remediate any errors that may occur and thus allows for the communication to be more reliable, while the framework does use encryption, encryption does not ensure integrity \citep{GUCCA}. The integrity of the communication is calculated using an 8-bit cyclic redundancy check (CRC-8). This allows errors to be recovered by using the discard chunk protocol (outlined in \fullref{sec:microprotocols}).

This requires the receiver to be able to communicate the integrity of the message back to the sender, so the sender can decide whether to resend the chunk or not. In order to do this the medium of communication must be both undisruptable and broadcasted.

The communication must be undisruptable because if the sender does not receive the integrity of the message, it will assume the receiver did not receive the message, and thus resend it.

It must also be broadcastable because there is no guarantee that the receiver will be able to determine the address of the sender, this is particularly true in the case of the TCP Acknowledgement bounce covert channel, as the sender will be using a local server to bounce the packets, and thus the receiver will not know the address of the sender.

A covert channel based on the Address Resolution Protocol (ARP) (outlined in \fullref{sec:ARP}) suited both of these requirements perfectly, as it is broadcasted, and it is required for the normal operation of a network, thus it is undisruptable. There are some applications where the ARP Beacon is not suitable for use:

\begin{itemize}
    \item The sender is not on the same network as the receiver.
    \item The network is solely IPv6 (using Neighbor Discovery Protocol (NDP) instead of ARP).
    \item The nodes of the network are statically configured.
\end{itemize}

Where ARP is not applicable, a different means of communication must be used, however, that is out of the scope of this paper.

The verification process is a challenge and response protocol, the sender will send a challenge to the receiver, and the receiver will respond with the integrity of the message. Verification of data chunks is performed when the method change protocol is sent, this is when the communication medium changes and thus the framework seeks to verify that the previous channel was successful. This does delay the verification of the data until the start of the next method transmission, but it does mean that the verification can be can become an implicit part of the method change protocol, which keeps the minimum channel size low, and reduces the number of packets sent. This method still allows a 
the challenge to be performed without changing the channel, by sending the method change protocol to the current channel index, this is useful for continual verification of the channel, but it does increase the number of packets sent.

\subsection{Improving the covertness of the response}
\label{sec:improving_arp}

To improve the covertness of the ARP Beacon, the sender will (if the channel is large enough) provide an offset to the receiver, and the receiver will XOR this with the result of the integrity check. Since the sender knows the correct integrity of the data, it can find an active host on the network and XOR the integrity with the host byte, the outcome of this is an offset that the receiver can use to make its ARP request look valid to an observer. This is only possible if the channel is large enough, but if it is not the receiver will assume no offset.

With the offset, the ARP Beacon is much more covert and less prone to detection from Aware active wardens as the adversary knows it is plausible that the channel is for legitimate use and not a channel \citep{GUCCA}. However, this is only true when the integrity of the data is correct, if the data is corrupted, then the request will point to the wrong address, which could raise suspicion. Unfortunately, the receiver cannot determine whether the integrity is correct without sending its response, so this is a tradeoff that must be made.

Some addresses are blacklisted from being used, for example, the address of the sender (as they are in communication, the receiver could send an ARP packet that is unrelated to the covert channel, which could cause issues). The broadcast and network addresses are also blacklisted, as they are not valid hosts on the network, and thus would be suspicious to an observer. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/Integrity.png}
    \caption{Integrity challenge and response (optional parts in brackets)}
    \label{fig:integrity}
\end{figure}

Since the sender knows what the response is supposed to be, it can await the response and succeed quickly (if it sees the expected response), otherwise, it will wait until the timeout expires (5 seconds by default). Unfortunately, the sender cannot accurately tell if the receiver has not received the packet, or if the integrity is incorrect since the host is assumed to be using ARP communication outside of the channel.

This challenge and response process can be performed irrespective of the underlying covert channel, but it might require limitations on the environment (just as ARP requires a local network). 

\subsection{The discard chunk protocol}

The discard chunk protocol tells the receiver to revert the last chunk commit, as the sender determined it was not valid. The receiver assumes the integrity is correct because most of the time it is, and sending a packet to the sender to verify that the last verification was correct is unnecessary, so instead the receiver will assume the last verification was correct unless specifically informed otherwise by the sender, this reduces the total number of microprotocols which is important to reduce the number of packets sent \citep{DRiCCBoCP}.

The sender must then resend the previous chunk of data again, but this would cause an issue to arise as the fields of the packets will also be identical, in some cases this can cause an active warden to detect the communication, to prevent this we use utilise the remaining space (the space after the microprotocols) in the packet by filling it with data, this data offsets the bits being sent (by however much space is available) and thus the following packets will have different fields.

\section{Channel failures}
\label{sec:channel_failures}

There are scenarios where the channel for communication no longer works, this could be of a change in the environment or a warden that has prevented the channel. In these scenarios the framework must be able to recover the communication effort, the sender and receiver need a fallback channel that they can use to restart communication. However, if the fallback channel was the one being blocked then the communication would have to end, even if other channels were viable.

To prevent this, a recovery mode is defined for the framework, in this mode the receiver is open to all channels, and the sender will iterate through possible channels until it finds one that works. To prevent this from happening unintentionally the recovery mode is only entered when:
\begin{itemize}
    \item The receiver has failed two consecutive integrity checks.
    \item The receiver has not received any covert data for an interval.
\end{itemize}

Either one of the above conditions will send the sender/receiver into recovery mode, and the other one will eventually do the same. The sender will purposely wait until the interval has passed before attempting to recover, this is to prevent the sender from trying to switch channels prior to the receiver entering the recovery mode. This interval is based on the time and packets of the last verified chunk (the number of packets between verification, and the time between verification), this interval must be exceeded by 50\% before the receiver will enter recovery, and the sender will wait for even longer before attempting to recover. It is important to note that since this time between verifications could naturally exceed the interval, the receiver will still act as if the current channel is viable, saving the data to the chunk (Although this chunk will be discarded implicitly if the channel is "recovered").

The recovery mode can be recovered with a specially crafted packet, this packet should begin with the sentinel signal (as if it was starting communication) followed by the length of verified data, and an offset. The offset is used for the same function here as it is in \fullref{sec:integrity}, however, it is used in combination with the length of verified data, which is the length of the last sender-verified data. There are some cases where the receiver will have to assume its last verification was valid, but in reality, the discard chunk failed to reach it, but the sender will always know the length of the data at the last verification.


Since this packet requires more space than the minimum channel size, there are some cases where it does not fit in a channel, in these cases it simply cannot be used, and the alternative is to recover to a method with a larger bit capacity, then switch to the higher scoring channel afterwards. While this requirement is not perfect, it is the best way to prevent receivers from breaking communication due to interference from external sources.

When the receiver is recovered, it will send an integrity check back to the sender so it knows that the recovery was successful, the intervals between verifications here will not be recorded since they may not be consistent between the sender and receiver.

\subsection{Penalising methods}
\label{sec:penalising}

This recovery process is not ideal for covert communication, and causes the sender to try multiple channels, if these other channels are blocked then it can raise suspicions, to discourage this we penalise methods.

When a method fails twice, causing the recovery process to occur, it receives a penalty of -90\% to its score. This penalty lasts for 30 packets of valid data communication and prevents the method from being chosen again unless there are no better alternatives. The reason we do not permanently block the protocol is that it can fail for temporary reasons, but we cannot know that until we try again, It is undesirable to constantly retry failing methods as if they are being caught by wardens it is much more suspicious for many packets to have been blocked rather than just a few.
